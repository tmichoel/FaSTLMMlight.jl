var documenterSearchIndex = {"docs":
[{"location":"introduction/","page":"Introduction","title":"Introduction","text":"CurrentModule = FaSTLMMlight","category":"page"},{"location":"introduction/#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"We consider the setup of Lippert et al. (2011), where:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"yinmathbbR^n is a response vector with values for n samples,\nXinmathbbR^ntimes d is a matrix with data of d covariates (fixed effects) in the same n samples,\nKinmathbbR^ntimes n is a positive semi-definite sample similarity matrix, scaled such that mathrmtr(K)=n,\nbetainmathbbR^d is the (unknown) vector of fixed effect weights,\nsigma^2 is the (unknown) variance explained by K,\nsigma_e^2 is the (unknown) residual error variance,\ndelta = fracsigma_e^2sigma^2 is the variance ratio,","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"and y is distributed as","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"y sim Nbigl( Xbeta sigma^2 K + sigma_e^2 Ibigr) = Nbigl( Xbeta sigma^2 (K + delta I)bigr)","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"where N denotes a multivariate normal distribution.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The unknown parameters (betasigma^2delta) are estimated by maximum-likelihood (or restricted maximum-likelihood, see below), that is, by minimizing the negative log-likelihood function","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"mathcalL = logdetbigl sigma^2 (K + delta I) bigr + frac1sigma^2 bigllangle y-Xbeta (K + delta I)^-1 (y-Xbeta)bigrrangle","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"where langle uvrangle=u^Tv=sum_i=1^n u_n v_n is the usual inner product on mathbbR^n; note that for any matrix AinmathbbR^ntimes n and vectors uvinmathbbR^n, langle uAvrangle=mathrmtr(vu^TA). ","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Analytic expressions for the maximum-likelihood estimates hatbeta and hatsigma^2 as a function of delta are easy to obtain:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"beginaligned\nhatbeta = bigl X^T(K+delta I)^-1Xbigr^-1\n  X^T(K+delta I)^-1 y \n  hatsigma^2 = frac1n bigllangle y-Xhatbeta (K+delta I)^-1 (y-Xhatbeta)bigrrangle \nendaligned","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Plugging these expressions into the negative log-likelihood results in a (non-convex) function of the parameter delta, which upto an additive constant is given by: ","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"mathcalL(delta) = logdet (K+delta I) + n log hatsigma^2","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"In Lippert et al. (2011), the eigenvalue decomposition of K is used to increase the efficiency of evaluating mathcalL(delta) for a range of delta values, and thereby speed up the process of finding the maximum-likelihood estimate hatdelta. However, their method still expresses the evaluation of hatbeta(delta) as the solution of a linear system (if the number of covariates d1). This implies that the gradient of mathcalL(delta) cannot be computed using automatic differentiation, which means that only gradient-free optimization algorithms can be used (Lippert et al. (2011) used a basic grid-based search).","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Instead, FaST-LMM light first uses the singular value decomposition of the fixed effects matrix X to express the negative log-likelihood on the space orthogonal to the columns of X (in other words, uses restricted maximum likelihood). Then the spectral decomposition of K on the restricted space is used in the same manner as in the original FaST-LMM method, which results in a restricted negative log-likelihood function mathcalL_R(delta) whose gradient can be evaluated using automatic differentiation.","category":"page"},{"location":"FaST-LMM-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"CurrentModule = FaSTLMMlight","category":"page"},{"location":"FaST-LMM-fullrank/#FaST-LMM-full-rank","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"","category":"section"},{"location":"FaST-LMM-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"fastlmm_fullrank\ndelta_mle_fullrank\nminus_log_like_fullrank\nsigma2_mle_fullrank\nbeta_mle_fullrank_lazy\ncreate_covariate_matrix\nproject_orth_covar\nsoftplus","category":"page"},{"location":"FaST-LMM-fullrank/#FaSTLMMlight.fastlmm_fullrank","page":"FaST-LMM full rank","title":"FaSTLMMlight.fastlmm_fullrank","text":"fastlmm_fullrank(y,K; covariates = [], mean = true)\n\nFor a linear mixed model / Gaussian process,\n\ny sim Nbigl(Xbeta sigma^2(K + delta I) bigr)\n\nwhere y is the response vector, X is a matrix of covariates,  and K is  a full-rank kernel matrix, compute the restricted maximum-likelihood estimates (REMLs) of the variance parameter sigma^2 and the variance ratio delta using FaST-LMM with a full-rank kernel matrix. Compared to the original FaST-LMM algorithm, we first project out the (optional) covariates, incl. an (optional) constant off-set (mean=true), from the response vector and the kernel matrix. This avoids all matrix computations in the variance parameter estimation. Estimates for the fixed effects beta are not computed.\n\n\n\n\n\n","category":"function"},{"location":"FaST-LMM-fullrank/#FaSTLMMlight.delta_mle_fullrank","page":"FaST-LMM full rank","title":"FaSTLMMlight.delta_mle_fullrank","text":"delta_mle_fullrank(λ, yr)\n\nCompute the MLE of the variance ratio δ given the eigenvalues of the kernel matrix and the rotated response vector by solving the non-convex optimization problem formulated in the FaST-LMM paper.\n\n\n\n\n\n","category":"function"},{"location":"FaST-LMM-fullrank/#FaSTLMMlight.minus_log_like_fullrank","page":"FaST-LMM full rank","title":"FaSTLMMlight.minus_log_like_fullrank","text":"minus_log_like_fullrank(δ, λ, yr)\n\nCompute the minus log-likelihood of the model, scaled by the number of samples and without constant factors, given the variance ratio δ, the eigenvalues of the kernel matrix, the rotated response vector and (optionally) the rotated covariates.\n\n\n\n\n\n","category":"function"},{"location":"FaST-LMM-fullrank/#FaSTLMMlight.sigma2_mle_fullrank","page":"FaST-LMM full rank","title":"FaSTLMMlight.sigma2_mle_fullrank","text":"sigma2_mle_fullrank(δ, λ, yr)\n\nCompute the MLE of the variance parameter given the variance ratio δ, the eigenvalues of the kernel matrix, and the rotated response vector.\n\n\n\n\n\n","category":"function"},{"location":"FaST-LMM-fullrank/#FaSTLMMlight.beta_mle_fullrank_lazy","page":"FaST-LMM full rank","title":"FaSTLMMlight.beta_mle_fullrank_lazy","text":"beta_mle_fullrank_lazy(y, K, X, σ², δ)\n\nLazy implementation of the MLE of the fixed effects weights given the response vector y, the kernel matrix K, the covariates X, the variance parameter σ² and the variance ratio δ. This function does not use spectral factorization, and should only be applied once, using the MLEs of the variance parameters.\n\n\n\n\n\n","category":"function"},{"location":"FaST-LMM-fullrank/#FaSTLMMlight.create_covariate_matrix","page":"FaST-LMM full rank","title":"FaSTLMMlight.create_covariate_matrix","text":"create_covariate_matrix(X; mean = true, n = 1)\n\nCreate the covariate matrix from the provided covariates with an intercept column if mean=true.\n\n\n\n\n\n","category":"function"},{"location":"FaST-LMM-fullrank/#FaSTLMMlight.project_orth_covar","page":"FaST-LMM full rank","title":"FaSTLMMlight.project_orth_covar","text":"project_orth_covar(y, K, X)\n\nProject out the covariates from the response vector and the kernel matrix.\n\n\n\n\n\n","category":"function"},{"location":"FaST-LMM-fullrank/#FaSTLMMlight.softplus","page":"FaST-LMM full rank","title":"FaSTLMMlight.softplus","text":"softplus(x)\n\nCompute the softplus function, i.e. log(1 + exp(x)), element-wise.\n\n\n\n\n\n","category":"function"},{"location":"listfunctions/","page":"List of functions","title":"List of functions","text":"CurrentModule = FaSTLMMlight","category":"page"},{"location":"listfunctions/#List-of-package-functions","page":"List of functions","title":"List of package functions","text":"","category":"section"},{"location":"listfunctions/","page":"List of functions","title":"List of functions","text":"","category":"page"},{"location":"","page":"Contents","title":"Contents","text":"CurrentModule = FaSTLMMlight","category":"page"},{"location":"#FaST-LMM-light-Documentation","page":"Contents","title":"FaST-LMM light Documentation","text":"","category":"section"},{"location":"","page":"Contents","title":"Contents","text":"","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"CurrentModule = FaSTLMMlight","category":"page"},{"location":"svd-fixed-effects/#SVD-of-the-fixed-effects","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"","category":"section"}]
}
