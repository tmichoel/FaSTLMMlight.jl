var documenterSearchIndex = {"docs":
[{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"CurrentModule = FaSTLMMlight","category":"page"},{"location":"fastlmm-fullrank/#FaST-LMM-full-rank","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"","category":"section"},{"location":"fastlmm-fullrank/#Spectral-decomposition-of-the-kernel-matrix-and-data-rotaton","page":"FaST-LMM full rank","title":"Spectral decomposition of the kernel matrix and data rotaton","text":"","category":"section"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"We first consider the scenario where K is defined by a square semi-positive definite matrix and K_22 has been computed by svd_fixed_effects. Following Lippert et al. (2011), we call this the \"full rank\" scenario, although neither K nor K_22 actually has to have full rank.","category":"page"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"The spectral decomposition of K_22 can be written as K_22=U Lambda U^T, with UinmathbbR^(n-d)times (n-d) unitary and LambdainmathbbR^(n-d)times (n-d) diagonal with non-negative diagonal elements lambda_i=Lambda_iigeq 0, which we assume are ordered, lambda_1geqlambda_2geq dots geq lambda_n-dgeq 0","category":"page"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"The columns of U are the eigenvectors of K_22, and we denote them as u_i inmathbbR^n-d, with K_22 u_i=lambda_i u_i. The matrix U can be used to rotate the data y_2:","category":"page"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"tildey = U^T y_2 in mathbbR^n-d","category":"page"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"with components","category":"page"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"tildey_i = langle u_iy_2ranglequad i=1dotsn-d","category":"page"},{"location":"fastlmm-fullrank/#Likelihood-function-and-variance-parameter-estimation","page":"FaST-LMM full rank","title":"Likelihood function and variance parameter estimation","text":"","category":"section"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"These results allow to express the terms in mathcalell_R ","category":"page"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"beginaligned\n   frac1n-dlogdet(K_22+delta I) = frac1n-dsum_i=1^n-d log(lambda_i+delta)\n  hatsigma^2 = frac1n-dlangle y_2(K_22+delta I)^-1 y_2rangle = frac1n-dsum_i=1^n-d frac1lambda_i+delta langle y_2u_irangle^2 = frac1n-dsum_i=1^n-d fractildey_i^2lambda_i+delta\nendaligned","category":"page"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"Note the crucial difference with the original FaST-LMM method. There the eigenvalue decomposition of the full matrix K is used to facilitate the computation of the negative log-likelihood mathcalL (see Introduction), which still involves the solution of a linear system to compute hatbeta. By working in the restricted space orthogonal to the fixed effects and using the eigenvalue decomposition of the reduced matrix K_22, we have obtained a restricted negative log-likelihood ell_R which, given lambda and tilde y is trivial to evaluate and differentiate by  automatic differentiation.","category":"page"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"The values of hatsigma^2 and ell_R  as a function of the parameter delta and vectors lambda and tilde y are computed by the functions sigma2_reml and neg_log_like","category":"page"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"sigma2_reml\nneg_log_like","category":"page"},{"location":"fastlmm-fullrank/#FaSTLMMlight.sigma2_reml","page":"FaST-LMM full rank","title":"FaSTLMMlight.sigma2_reml","text":"sigma2_reml(δ, λ, yr)\n\nCompute the REML of the variance parameter given the variance ratio δ, the eigenvalues of the kernel matrix, and the rotated response vector.\n\n\n\n\n\n","category":"function"},{"location":"fastlmm-fullrank/#FaSTLMMlight.neg_log_like","page":"FaST-LMM full rank","title":"FaSTLMMlight.neg_log_like","text":"neg_log_like(δ, λ, yr)\n\nCompute the negative (restircted) log-likelihood of the model, scaled by the number of samples and without constant factors, given the variance ratio δ, the eigenvalues of the kernel matrix, and the rotated response vector.\n\n\n\n\n\n","category":"function"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"The optimization of the function ell_R is done by the function delta_reml using the LBFGS algorithm. Because delta must be greater than zero, we write delta as the softplus function of an unconstrained variable x, that is delta=log(1+e^x), and optimize with respect to x","category":"page"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"delta_reml\nsoftplus","category":"page"},{"location":"fastlmm-fullrank/#FaSTLMMlight.delta_reml","page":"FaST-LMM full rank","title":"FaSTLMMlight.delta_reml","text":"delta_reml(λ, yr)\n\nCompute the REML of the variance ratio δ given the eigenvalues of the kernel matrix and the rotated response vector by solving the non-convex optimization problem formulated in the FaST-LMM paper.\n\n\n\n\n\n","category":"function"},{"location":"fastlmm-fullrank/#FaSTLMMlight.softplus","page":"FaST-LMM full rank","title":"FaSTLMMlight.softplus","text":"softplus(x)\n\nCompute the softplus function, i.e. log(1 + exp(x)), element-wise.\n\n\n\n\n\n","category":"function"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"fastlmm_fullrank\nbeta_mle_fullrank_lazy","category":"page"},{"location":"fastlmm-fullrank/#FaSTLMMlight.fastlmm_fullrank","page":"FaST-LMM full rank","title":"FaSTLMMlight.fastlmm_fullrank","text":"fastlmm_fullrank(y,K; covariates = [], mean = true)\n\nFor a linear mixed model / Gaussian process,\n\ny sim Nbigl(Xbeta sigma^2(K + delta I) bigr)\n\nwhere y is the response vector, X is a matrix of covariates,  and K is  a full-rank kernel matrix, compute the restricted maximum-likelihood estimates (REMLs) of the variance parameter sigma^2 and the variance ratio delta using FaST-LMM with a full-rank kernel matrix. Compared to the original FaST-LMM algorithm, we first project out the (optional) covariates, incl. an (optional) constant off-set (mean=true), from the response vector and the kernel matrix. This avoids all matrix computations in the variance parameter estimation. Estimates for the fixed effects beta are not computed.\n\n\n\n\n\n","category":"function"},{"location":"fastlmm-fullrank/#FaSTLMMlight.beta_mle_fullrank_lazy","page":"FaST-LMM full rank","title":"FaSTLMMlight.beta_mle_fullrank_lazy","text":"beta_mle_fullrank_lazy(y, K, X, σ², δ)\n\nLazy implementation of the MLE of the fixed effects weights given the response vector y, the kernel matrix K, the covariates X, the variance parameter σ² and the variance ratio δ. This function does not use spectral factorization, and should only be applied once, using the MLEs of the variance parameters.\n\n\n\n\n\n","category":"function"},{"location":"fastlmm-fullrank/#Fixed-effects-weights-using-the-rotated-basis","page":"FaST-LMM full rank","title":"Fixed effects weights using the rotated basis","text":"","category":"section"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"The fixed effects weights need to be computed only once, after hatdelta has been estimated, hatbeta(hatdelta) is computed using the formula in Fixed effects weights. Using the eigendecomposition of K_22 and the rotated data tilde y = U^Ty_2 we obtain","category":"page"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"beginaligned\nhat beta(hatdelta) = W Gamma^-1 ( y_1 - K_12 (K_22+hatdelta I)^-1 y_2 )\n= W Gamma^-1 ( y_1 - K_12 U(Lambda+hatdelta I)^-1 U^Ty_2 )\n= W Gamma^-1 ( y_1 - K_12 U (Lambda+hatdelta I)^-1 tilde y )\nendaligned","category":"page"},{"location":"fastlmm-fullrank/","page":"FaST-LMM full rank","title":"FaST-LMM full rank","text":"The components of the vector (Lambda+hatdelta I) tilde y are easily computed elementwise as tilde y_i(lambda_i+hatdelta).","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"CurrentModule = FaSTLMMlight","category":"page"},{"location":"introduction/#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"We consider the setup of Lippert et al. (2011), where:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"yinmathbbR^n is a response vector with values for n samples,\nXinmathbbR^ntimes d is a matrix with data of d covariates (fixed effects) in the same n samples,\nKinmathbbR^ntimes n is a positive semi-definite sample similarity matrix, scaled such that mathrmtr(K)=n,\nmu is an (unknown) overall mean parameter,\nbetainmathbbR^d is the (unknown) vector of fixed effect weights,\nsigma^2 is the (unknown) variance explained by K,\nsigma_e^2 is the (unknown) residual error variance,\ndelta = fracsigma_e^2sigma^2 is the variance ratio,","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"and y is distributed as","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"y sim Nbigl(mu + Xbeta sigma^2 K + sigma_e^2 Ibigr) = Nbigl( Xbeta sigma^2 (K + delta I)bigr)","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"where N denotes a multivariate normal distribution.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"By adding a column of ones to X we can absorb the parameter mu in the vector of fixed effect weights beta. High-level functions in this package all accept a parameter mean=true which will call this operation:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"create_covariate_matrix","category":"page"},{"location":"introduction/#FaSTLMMlight.create_covariate_matrix","page":"Introduction","title":"FaSTLMMlight.create_covariate_matrix","text":"create_covariate_matrix(X; mean = true, n = 1)\n\nCreate the covariate matrix from the provided covariates with an intercept column if mean=true.\n\n\n\n\n\n","category":"function"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Low-level functions all work with the model where mu is not explicitly modelled and the unknown parameters are (betasigma^2delta). If mean=true then in the output the overall estimated mean corresponds to the first element beta1.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The parameters (betasigma^2delta) are estimated by maximum-likelihood (or restricted maximum-likelihood, see below), that is, by minimizing the negative log-likelihood function","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"mathcalL = logdetbigl sigma^2 (K + delta I) bigr + frac1sigma^2 bigllangle y-Xbeta (K + delta I)^-1 (y-Xbeta)bigrrangle","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"where langle uvrangle=u^Tv=sum_i=1^n u_n v_n is the usual inner product on mathbbR^n; note that for any matrix AinmathbbR^ntimes n and vectors uvinmathbbR^n, langle uAvrangle=mathrmtr(vu^TA). ","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Analytic expressions for the maximum-likelihood estimates hatbeta and hatsigma^2 as a function of delta are easy to obtain:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"beginaligned\nhatbeta = bigl X^T(K+delta I)^-1Xbigr^-1\n  X^T(K+delta I)^-1 y \n  hatsigma^2 = frac1n bigllangle y-Xhatbeta (K+delta I)^-1 (y-Xhatbeta)bigrrangle \nendaligned","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Plugging these expressions into the negative log-likelihood results in a (non-convex) function of the parameter delta, which upto an additive constant is given by: ","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"mathcalL(delta) = logdet (K+delta I) + n log hatsigma^2","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"In Lippert et al. (2011), the eigenvalue decomposition of K is used to increase the efficiency of evaluating mathcalL(delta), and thereby speed up the process of finding the maximum-likelihood estimate hatdelta. However, their method still expresses the evaluation of hatbeta(delta) as the solution of a linear system (if the number of covariates d1). This implies that the gradient of mathcalL(delta) cannot be computed using automatic differentiation, which means that only gradient-free optimization algorithms can be used (Lippert et al. (2011) used a basic grid-based search).","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Instead, FaST-LMM light first uses the singular value decomposition of the fixed effects matrix X to express the negative log-likelihood on the space orthogonal to the columns of X (in other words, uses restricted maximum likelihood). Then the spectral decomposition of K on the restricted space is used in the same manner as in the original FaST-LMM method, which results in a restricted negative log-likelihood function mathcalL_R(delta) whose gradient can be evaluated using automatic differentiation.","category":"page"},{"location":"listfunctions/","page":"List of functions","title":"List of functions","text":"CurrentModule = FaSTLMMlight","category":"page"},{"location":"listfunctions/#List-of-package-functions","page":"List of functions","title":"List of package functions","text":"","category":"section"},{"location":"listfunctions/","page":"List of functions","title":"List of functions","text":"","category":"page"},{"location":"","page":"Contents","title":"Contents","text":"CurrentModule = FaSTLMMlight","category":"page"},{"location":"#FaST-LMM-light-Documentation","page":"Contents","title":"FaST-LMM light Documentation","text":"","category":"section"},{"location":"","page":"Contents","title":"Contents","text":"","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"CurrentModule = FaSTLMMlight","category":"page"},{"location":"svd-fixed-effects/#SVD-of-the-fixed-effects","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"","category":"section"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"We assume that the number of fixed effects is less than the number of  samples, d  n, and that the matrix X of fixed effects has full rank, mathrmrank(X)=d. We can then write the \"thin\" singular value decomposition of X as X = V_1 Gamma W^T, where V_1inmathbbR^ntimes d with V_1^TV_1=I, Gamma inmathbbR^dtimes d diagonal with gamma_i=Gamma_ii0 for all i, and WinmathbbR^dtimes d with W^TW=WW^T=I. Furthermore there exists V_2inmathbbR^ntimes (n-d) with V_2^TV_2=I, V_1^TV_2=0 and V_1V_1^T+V_2V_2^T=I, i.e. the matrix V=(V_1 V_2) is unitary, and V_1V_1^T and V_2V_2^T are the orthogonal projection matrices on the range and (left) null space of X, respectively.","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"Using the singular value decomposition of X, we can write any matrix AinmathbbR^ntimes n and vector yinmathbbR^n in block matrix/vector notation as","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"beginaligned\n  A =\n       beginpmatrix\n         A_11  A_12\n         A_21  A_22\n       endpmatrixtextwherequad\n        A_ij = V_i^T A V_j\n  y =\n      beginpmatrix\n        y_1 y_2 \n      endpmatrix textwherequad\n  y_i = V_i^T y\nendaligned","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"Using standard results for the inverse and determinant of a block matrix, we have","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"  logdet(A) = logdet(A_11) + logdet(A_22-A_21A_11^-1A_12) = log det(A_11) - logdet(A^-1_22)","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"Furthermore, we have","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"  X (X^T A X)^-1 X^T = V_1Gamma W^T (WGamma V_1^T A V_1Gamma W^T)^-1 W Gamma V_1^T  = V_1 (V_1^T A V_1)^-1 V_1^T = V_1 (A_11)^-1 V_1^T","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"Using this for the specific case where A=(K+delta I)^-1, together with the identity y=(V_1V_1^T+V_2V_2^T)y = V_1y_1 + V_2y_2, in the equation ","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"  bigllangle y-Xhatbeta A (y-Xhatbeta)bigrrangle= langle yA yrangle - langle y A X (X^TAX)^-1 X^T A yrangle\n  = bigllangle y bigl(A - A X (X^TAX)^-1 X^T Abigr) y bigrrangle","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"gives","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"beginaligned\n  bigllangle y-Xhatbeta A (y-Xhatbeta)bigrrangle\n  qquad=\n                    beginpmatrix\n                      y_1^T   y_2^T\n                    endpmatrix\n                    beginpmatrix\n                      A_11  A_12\n                      A_21  A_22\n                    endpmatrix\n                    beginpmatrix\n                      y_1 y_2\n                    endpmatrix\n  -beginpmatrix\n    y_1^T   y_2^T\n  endpmatrix\n   beginpmatrix\n     A_11 (A_11)^-1 A_11  A_11 (A_11)^-1 A_12\n     A_21A_11 (A_11)^-1  A_21 (A_11)^-1A_12\n   endpmatrix\n   beginpmatrix\n     y_1 y_2\n   endpmatrix \n  qquad= beginpmatrix\n    y_1^T   y_2^T\n  endpmatrix\n            beginpmatrix\n              0  0\n              0  A_22 - A_21 (A_11)^-1A_12\n            endpmatrix\n                        beginpmatrix\n                          y_1 y_2\n                        endpmatrix\n  qquad= langle y_2(A^-1)_22^-1 y_2rangle\nendaligned","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"Because using the maximum-likelihood estimates hatbeta has the effect of projecting out the fixed effects from the response y in the residual variance, it is common to also remove the contribution of the fixed effect space from the determinant term in the log-likelihood, i.e. replace","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"beginaligned\n  logdet(K+delta I) = -logdetbigl(K+delta I)^-1bigr = -logdet(A) \n  to logdet(A^-1_22) = logdetbiglK_22+delta Ibigr\nendaligned","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"and consider the residual or restricted negative log-likelihood function","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"  mathcalL_R(sigma^2delta) = logdetbiglsigma^2(K_22+delta I)bigr + frac1sigma^2 langle y_2(K_22+delta I)^-1 y_2rangle","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"This results in the restricted  maximum-likelihood estimate","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"  hatsigma^2 = frac1n-d langle y_2(K_22+delta I)^-1 y_2rangle","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"which is n(n-d) times the unrestricted maximum-likelihood estimate. Plugging this in the restricted negative log-likelihood function gives, upto an additive constant","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"  mathcalL_R(delta) = logdetbigl(K_22+delta Ibigr) + (n-d)log hatsigma^2","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"Because the sample size n may be large, we scale this function by n-d to obtain","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"ell_R(delta) = frac1n-d mathcalL_R(delta) = frac1n-dlogdetbigl(K_22+delta Ibigr) + log hatsigma^2","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"which needs to be minimized to obtain the restricted maximum-likelihood estimate hatdelta.","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"If K is given as a square matrix, the projection of y and K onto the space orthogonal to the columns of X is done by the function:","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"svd_fixed_effects","category":"page"},{"location":"svd-fixed-effects/#FaSTLMMlight.svd_fixed_effects","page":"SVD of the fixed effects","title":"FaSTLMMlight.svd_fixed_effects","text":"svd_fixed_effects(y, K, X)\n\nCompute the SVD of the covariate matrix X and return the block deomposition of the response vector y and the kernel matrix K with respect to the orthogonal complement of the column space of X.\n\n\n\n\n\n","category":"function"},{"location":"svd-fixed-effects/#Fixed-effects-weights","page":"SVD of the fixed effects","title":"Fixed effects weights","text":"","category":"section"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"The maximum-likelihood estimate hatbeta for the fixed effects weights (see Introduction) can also be expressed conveniently using the same block matrix notation. Still writing A=(K+delta I)^-1 we have","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"beginaligned\nhat beta = (X^TAX)^-1 X^T A y \n= W Gamma^-1 (A_11)^-1 Gamma^-1 W^T W Gamma V_1^T A y\n= W Gamma^-1 (A_11)^-1 (Ay)_1\n= W Gamma^-1 (A_11)^-1 (A_11y_1 + A_12y_2)\n= W Gamma^-1 ( y_1 + (A_11)^-1 A_12 y_2 )\nendaligned","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"Again using properties of the inverse of a block matrix, we have (A_11)^-1 A_12 = - B_12 (B_22)^-1 where B=A^-1=K+delta I, or","category":"page"},{"location":"svd-fixed-effects/","page":"SVD of the fixed effects","title":"SVD of the fixed effects","text":"hat beta = W Gamma^-1 ( y_1 - K_12 (K_22+delta I)^-1 y_2 )","category":"page"}]
}
