<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Introduction · FaST-LMM light</title><meta name="title" content="Introduction · FaST-LMM light"/><meta property="og:title" content="Introduction · FaST-LMM light"/><meta property="twitter:title" content="Introduction · FaST-LMM light"/><meta name="description" content="Documentation for FaST-LMM light."/><meta property="og:description" content="Documentation for FaST-LMM light."/><meta property="twitter:description" content="Documentation for FaST-LMM light."/><meta property="og:url" content="https://tmichoel.github.io/FaSTLMMlight.jl/introduction/"/><meta property="twitter:url" content="https://tmichoel.github.io/FaSTLMMlight.jl/introduction/"/><link rel="canonical" href="https://tmichoel.github.io/FaSTLMMlight.jl/introduction/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">FaST-LMM light</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Contents</a></li><li class="is-active"><a class="tocitem" href>Introduction</a></li><li><a class="tocitem" href="../svd-fixed-effects/">SVD of the fixed effects</a></li><li><a class="tocitem" href="../fastlmm-fullrank/">FaST-LMM full rank</a></li><li><a class="tocitem" href="../listfunctions/">List of functions</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Introduction</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Introduction</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/tmichoel/FaSTLMMlight.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/tmichoel/FaSTLMMlight.jl/blob/main/docs/src/introduction.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h1><p>We consider the setup of <a href="https://europepmc.org/article/med/21892150">Lippert et al. (2011)</a>, where:</p><ul><li><span>$y\in\mathbb{R}^n$</span> is a response vector with values for <span>$n$</span> samples,</li><li><span>$X\in\mathbb{R}^{n\times d}$</span> is a matrix with data of <span>$d$</span> covariates (fixed effects) in the same <span>$n$</span> samples,</li><li><span>$K\in\mathbb{R}^{n\times n}$</span> is a positive semi-definite sample similarity matrix, scaled such that <span>$\mathrm{tr}(K)=n$</span>,</li><li><span>$\mu$</span> is an (unknown) overall mean parameter,</li><li><span>$\beta\in\mathbb{R}^d$</span> is the (unknown) vector of fixed effect weights,</li><li><span>$\sigma^2$</span> is the (unknown) variance explained by <span>$K$</span>,</li><li><span>$\sigma_e^2$</span> is the (unknown) residual error variance,</li><li><span>$\delta = \frac{\sigma_e^2}{\sigma^2}$</span> is the variance ratio,</li></ul><p>and <span>$y$</span> is distributed as</p><p class="math-container">\[y \sim N\bigl(\mu + X\beta, \sigma^2 K + \sigma_e^2 I\bigr) = N\bigl( \mu + X\beta, \sigma^2 (K + \delta I)\bigr)\]</p><p>where <span>$N$</span> denotes a multivariate normal distribution.</p><p>By adding a column of ones to <span>$X$</span> we can absorb the parameter <span>$\mu$</span> in the vector of fixed effect weights <span>$\beta$</span>. High-level functions in this package all accept a parameter <code>mean=true</code> which will call this operation:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FaSTLMMlight.create_covariate_matrix" href="#FaSTLMMlight.create_covariate_matrix"><code>FaSTLMMlight.create_covariate_matrix</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">create_covariate_matrix(X; mean = true, n = 1)</code></pre><p>Create the covariate matrix from the provided covariates with an intercept column if <code>mean=true</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/tmichoel/FaSTLMMlight.jl/blob/0b190e871e99d1fb5ec54ea6d67d908678336984/src/fastlmm-core.jl#L163-L167">source</a></section></article><p>Low-level functions all work with the model where <span>$\mu$</span> is not explicitly modelled and the unknown parameters are <span>$(\beta,\sigma^2,\delta)$</span>. If <code>mean=true</code> then in the output the overall estimated mean corresponds to the first element <span>$\beta[1]$</span>.</p><p>The parameters <span>$(\beta,\sigma^2,\delta)$</span> are estimated by maximum-likelihood (or restricted maximum-likelihood, see below), that is, by minimizing the negative log-likelihood function</p><p class="math-container">\[\mathcal{L} = \log\det\bigl[ \sigma^2 (K + \delta I) \bigr] + \frac1{\sigma^2} \bigl\langle y-X\beta, (K + \delta I)^{-1} (y-X\beta)\bigr\rangle,\]</p><p>where <span>$\langle u,v\rangle=u^Tv=\sum_{i=1}^n u_i v_i$</span> is the usual inner product on <span>$\mathbb{R}^n$</span>; note that for any matrix <span>$A\in\mathbb{R}^{n\times n}$</span> and vectors <span>$u,v \in \mathbb{R]^n$</span>, <span>$\langle u,Av\rangle=\mathrm{tr}(vu^TA)$</span>. </p><p>Analytic expressions for the maximum-likelihood estimates <span>$\hat{\beta}$</span> and <span>$\hat{\sigma}^2$</span> as a function of <span>$\delta$</span> are easy to obtain:</p><p class="math-container">\[\begin{aligned}
\hat\beta &amp;= \bigl[ X^T(K+\delta I)^{-1}X\bigr]^{-1}
  X^T(K+\delta I)^{-1} y \\
  \hat{\sigma}^2 &amp;= \frac1n \bigl\langle y-X\hat\beta, (K+\delta I)^{-1} (y-X\hat\beta)\bigr\rangle, 
\end{aligned}\]</p><p>Plugging these expressions into the negative log-likelihood results in a (non-convex) function of the parameter <span>$\delta$</span>, which upto an additive constant is given by: </p><p class="math-container">\[\mathcal{L}(\delta) = \log\det (K+\delta I) + n \log \hat{\sigma}^2\]</p><p>In <a href="https://europepmc.org/article/med/21892150">Lippert et al. (2011)</a>, the eigenvalue decomposition of <span>$K$</span> is used to increase the efficiency of evaluating <span>$\mathcal{L}(\delta)$</span>, and thereby speed up the process of finding the maximum-likelihood estimate <span>$\hat\delta$</span>. However, their method still expresses the evaluation of <span>$\hat\beta(\delta)$</span> as the solution of a linear system (if the number of covariates <span>$d&gt;1$</span>). This implies that the gradient of <span>$\mathcal{L}(\delta)$</span> cannot be computed using <a href="https://julianlsolvers.github.io/Optim.jl/stable/user/gradientsandhessians/#Automatic-differentiation">automatic differentiation</a>, which means that only <a href="https://julianlsolvers.github.io/Optim.jl/stable/algo/nelder_mead/">gradient-free optimization algorithms</a> can be used (<a href="https://europepmc.org/article/med/21892150">Lippert et al. (2011)</a> used a basic grid-based search).</p><p>Instead, <a href="https://github.com/tmichoel/FaSTLMMlight.jl">FaST-LMM light</a> first uses the singular value decomposition of the fixed effects matrix <span>$X$</span> to express the negative log-likelihood on the space orthogonal to the columns of <span>$X$</span> (in other words, uses <a href="https://en.wikipedia.org/wiki/Restricted_maximum_likelihood">restricted maximum likelihood</a>). Then the spectral decomposition of <span>$K$</span> on the restricted space is used in the same manner as in the original FaST-LMM method, which results in a restricted negative log-likelihood function <span>$\mathcal{L}_R(\delta)$</span> whose gradient <em>can</em> be evaluated using <a href="https://julianlsolvers.github.io/Optim.jl/stable/user/gradientsandhessians/#Automatic-differentiation">automatic differentiation</a>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Contents</a><a class="docs-footer-nextpage" href="../svd-fixed-effects/">SVD of the fixed effects »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Saturday 8 June 2024 10:53">Saturday 8 June 2024</span>. Using Julia version 1.10.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
